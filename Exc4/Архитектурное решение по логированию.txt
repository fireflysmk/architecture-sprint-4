==========================
Логгирование
==========================
Логи для сбора

Онлайн-магазин:
Создание заказа (INITIATED)
Загрузка файла (FILE_UPLOADED)
Подтверждение заказа (SUBMITTED)

CRM:
Подтверждение заказа (MANUFACTURING_APPROVED)
Закрытие заказа (CLOSED)

MES:
Расчёт стоимости (PRICE_CALCULATED)
Начало производства (MANUFACTURING_STARTED)
Завершение производства (MANUFACTURING_COMPLETED)
Упаковка (PACKAGING)
Отправка (SHIPPED)

RabbitMQ:
Передача сообщений между CRM и MES

Список необходимых логов (уровень INFO):

Изменение статуса заказа:
Время, идентификатор покупателя, номер заказа, новый статус

Запросы к API:
Время, метод, endpoint, статус ответа, время выполнения

Сообщения в RabbitMQ:
Время, идентификатор сообщения, статус обработки

Другие уровни логирования:
DEBUG: Для отладки сложных сценариев (например, расчёт стоимости в MES, детальный лог вызова, полное xml/json тело сообщения )

WARN: Для нестандартных ситуаций, которые не приводят к ошибке (например, не найдено описание заказа или не заполнены другие необязательные для работы поля)

ERROR: Для критических ошибок (например, потеря сообщения в RabbitMQ)
Ошибки при обработке заказа:
Время, идентификатор заказа, описание ошибки

==========================
Мотивация
==========================

- Ускорение диагностики проблем: Логи позволят быстро находить причины ошибок и нестандартных ситуаций
- Снижение нагрузки на поддержку: Разработчики и специалисты поддержки смогут самостоятельно анализировать проблемы, не опираясь на слова клиентов
- Улучшение качества системы: Анализ логов поможет выявить узкие места и улучшить производительность
- Поддержка бизнеса: Логирование поможет обосновать необходимость изменений и инвестиций

Технические и бизнес-метрики:
- Среднее время диагностики проблем
- Количество ошибок, выявленных через логи
- Удовлетворённость клиентов (CSAT)
- Среднее время выполнения заказа
- Количество жалоб клиентов

Приоритеты:
- CRM и MES: Эти системы критичны для обработки заказов
- RabbitMQ: Интеграция между системами часто является источником проблем
- Онлайн-магазин: Логирование поможет улучшить пользовательский опыт

==========================
Предлагаемое решение
==========================

https://drive.google.com/file/d/1bxbE-7A39EV7SgcGiF9-wMvhJfYUfx68/view?usp=drive_link

Технологии:

ELK-стек (Elasticsearch, Logstash, Kibana):
- Elasticsearch для хранения логов
- Logstash для сбора и обработки логов
- мKibana для визуализации и анализа

Fluentd: Для сбора логов с контейнеров и приложений
- Внедрение Fluentd для сбора логов с онлайн-магазина, CRM, MES и RabbitMQ

Обработка логов:
- Настройка Logstash для фильтрации и обогащения логов

Хранение логов:
- Использование Elasticsearch для хранения логов

Визуализация:
- Настройка Kibana для создания дашбордов и анализа логов

Политика безопасности:
Аутентификация и авторизация:
- Доступ к Kibana только для сотрудников с ролью «Поддержка» или «Разработчик»

Шифрование данных:
- Использование TLS для передачи логов между компонентами

Маскирование чувствительных данных:
- Маскирование персональных данных (например, идентификаторов пользователей) в логах

Логирование доступа:
- Ведение логов доступа к Kibana и Elasticsearch

Политика хранения логов

Хранение логов:
- Логи хранятся в отдельных индексах для каждой системы (онлайн-магазин, CRM, MES, RabbitMQ)

Срок хранения:
- 30 дней для логов уровня INFO
- 90 дней для логов уровня ERROR

Размер логов:
- Оценка объёма логов: ~10 ГБ в день

Настройка ротации логов для предотвращения переполнения

=====================================
6 Мероприятия для анализа логов
=====================================
Алертинг:
- Настройка алертов в Kibana для уведомлений о критических ошибках (например, HTTP 500)
Пример: Если количество ошибок превышает порог, отправлять уведомление в Slack

Поиск аномалий:
- Настройка правил для обнаружения аномалий (например, резкий рост количества запросов)
Пример: Если количество запросов к API увеличилось в 10 раз за минуту, завести тикет для анализа

Анализ производительности:
- Создание дашбордов для анализа времени выполнения запросов и этапов заказа


====================================================
Дополнительное задание: Критерии выбора технологии
====================================================
Критерии:

Масштабируемость:

Технология должна поддерживать рост объёма логов

ELK: Хорошо масштабируется, но требует ресурсов

Простота интеграции:

Технология должна легко интегрироваться с существующей инфраструктурой

Fluentd: Поддерживает множество источников логов

Производительность:

Технология должна обеспечивать быструю обработку и поиск логов

Elasticsearch: Оптимизирован для поиска и анализа

Стоимость:

Технология должна быть экономически эффективной

ELK: Бесплатен для базового использования, но требует ресурсов

Поддержка сообщества:

Технология должна иметь активное сообщество и документацию

ELK: Широко используется, множество ресурсов и плагинов

Обоснование выбора ELK:

Плюсы: Масштабируемость, производительность, активное сообщество

Минусы: Требует ресурсов, сложность настройки для больших объёмов данных


